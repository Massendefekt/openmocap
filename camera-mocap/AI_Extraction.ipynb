{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'av'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a77d48ece4e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mav\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'av'"
     ]
    }
   ],
   "source": [
    "import av\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using AI to extract features\n",
    "\n",
    "A pretrained NN model is used to extract features from images.\n",
    "The \"marker\" is the center of the bounding box created around the\n",
    "feature (e.g. around a hand)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '' # path to model\n",
    "detection_graph = tf.Graph()\n",
    "sess = {}\n",
    "\n",
    "# import the model\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(path, 'rb') as f:\n",
    "        serialized = f.read()\n",
    "        od_graph_def.ParseFromString(serialized)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "    sess = tf.Session(graph=detection_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ''  # path to video file\n",
    "\n",
    "container = v.open(path)\n",
    "\n",
    "frames = []\n",
    "# read the video file\n",
    "for packet in container.demux():\n",
    "    for frame in packet.decode():\n",
    "        if frame.type == 'video':\n",
    "            frame = frame.to_image()\n",
    "            frames.append(np.array(frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_boxes = []  # list to store the detected objects to\n",
    "detected_scores = []\n",
    "\n",
    "# actual detection\n",
    "for frame in frames:\n",
    "    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "    detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "    detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "    detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "    \n",
    "    frame_expanded = np.expand_dims(frame, axis=0)\n",
    "    (boxes, scores, classes, num) = sess.run([detection_boxes, detection_scores, detection_classes, num_detections], feed_dict={image_tensor: frame_expanded})\n",
    "    boxes = np.squeeze(boxes)\n",
    "    scores = np.squeeze(scores)\n",
    "    detected_boxes.append(boxes)\n",
    "    detected_scores.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the center of the detection boxes, we actually only track this point\n",
    "thresh = 0.8  # threshold for inclusion\n",
    "\n",
    "image_dimensions = (0, 0)  # height x width\n",
    "\n",
    "centers = []\n",
    "for m, boxes in enumerate(detected_boxes):\n",
    "    box_centers = []  # centers per image\n",
    "    for n, box in enumerate(boxes):\n",
    "        if thresh =< detected_scores[m][n]:\n",
    "            # calculate center:\n",
    "            y = ((box[2] - box[0]) * image_dimensions[0]) / 2\n",
    "            x = ((box[3] - box[1]) * image_dimensions[1]) / 2\n",
    "            box_centers.append((x, y))\n",
    "    centers.append(box_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = ''  # path to file \n",
    "np.save(file, np.array(centers))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
